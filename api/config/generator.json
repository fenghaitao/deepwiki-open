{
  "default_provider": "github_copilot",
  "providers": {
    "github_copilot": {
      "client_class": "GitHubCopilotClient",
      "default_model": "gpt-4o",
      "supportsCustomModel": true,
      "models": {
        "gpt-4o": {
          "temperature": 0.7,
          "top_p": 0.8,
          "max_tokens": 4096
        },
        "gpt-4o-mini": {
          "temperature": 0.7,
          "top_p": 0.8,
          "max_tokens": 4096
        },
        "o1-preview": {
          "temperature": 1.0,
          "max_tokens": 4096
        },
        "o1-mini": {
          "temperature": 1.0,
          "max_tokens": 4096
        },
        "claude-3-5-sonnet": {
          "temperature": 0.7,
          "top_p": 0.8,
          "max_tokens": 8192
        }
      }
    },
    "dashscope": {
      "client_class": "DashscopeClient",
      "default_model": "qwen-plus",
      "supportsCustomModel": true,
      "models": {
        "qwen-plus": {
          "temperature": 0.1,
          "top_p": 0.8,
          "max_tokens": 4000
        },
        "qwen-turbo": {
          "temperature": 0.1,
          "top_p": 0.8,
          "max_tokens": 4000
        },
        "qwen-max": {
          "temperature": 0.1,
          "top_p": 0.8,
          "max_tokens": 4000
        },
        "qwen-long": {
          "temperature": 0.1,
          "top_p": 0.8,
          "max_tokens": 4000
        },
        "deepseek-r1": {
          "temperature": 0.1,
          "top_p": 0.8,
          "max_tokens": 4000
        }
      }
    },
    "iflow": {
      "client_class": "OpenAIClient",
      "default_model": "Qwen3-Coder",
      "supportsCustomModel": true,
      "base_url": "https://apis.iflow.cn/v1",
      "api_key_env": "IFLOW_API_KEY",
      "models": {
        "Qwen3-Coder": {
          "temperature": 0.1,
          "top_p": 0.8,
          "max_tokens": 4000
        },
        "qwen-plus": {
          "temperature": 0.1,
          "top_p": 0.8,
          "max_tokens": 4000
        },
        "qwen-turbo": {
          "temperature": 0.1,
          "top_p": 0.8,
          "max_tokens": 4000
        },
        "qwen-max": {
          "temperature": 0.1,
          "top_p": 0.8,
          "max_tokens": 4000
        },
        "qwen-long": {
          "temperature": 0.1,
          "top_p": 0.8,
          "max_tokens": 4000
        }
      }
    }
  }
}